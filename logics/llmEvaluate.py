# llmEvaluate.py
from google import generativeai as gemini
from config import GEMINI_API_KEY
import json, re, traceback

def _log(msg: str):
    print(msg.replace("```", "'''"))  # tr√°nh highlight markdown

# ------------------ Setup Gemini ------------------
try:
    gemini.configure(api_key=GEMINI_API_KEY)
    _log("‚úÖ Gemini API configured successfully.")
except Exception as e:
    _log(f"‚ùå Failed to configure Gemini API: {e}")


# ------------------ JSON Cleaning Helpers ------------------
def _strip_code_fence(text: str) -> str:
    """Lo·∫°i b·ªè ```json ... ``` ho·∫∑c ``` ... ``` ·ªü ƒë·∫ßu/cu·ªëi."""
    t = text.strip()
    t = re.sub(r"^\s*```json\s*", "", t, flags=re.IGNORECASE)
    t = re.sub(r"^\s*```\s*", "", t)
    t = re.sub(r"\s*```\s*$", "", t)
    return t.strip()


def _extract_json_block(text: str) -> str:
    """
    T√¨m ra kh·ªëi JSON h·ª£p l·ªá trong text.
    Th·ª© t·ª±:
      1. Trong ```json``` ho·∫∑c ```
      2. B·∫±ng d·∫•u { ... }
    """
    # C√≥ th·ªÉ n·∫±m trong code fence
    m = re.search(r"```json\s*(\{.*?\})\s*```", text, flags=re.IGNORECASE | re.DOTALL)
    if m:
        return m.group(1).strip()

    m = re.search(r"```\s*(\{.*?\})\s*```", text, flags=re.DOTALL)
    if m:
        return m.group(1).strip()

    # Fallback: t√¨m d·∫•u ngo·∫∑c ƒë·∫ßu‚Äìcu·ªëi
    s = text
    start = s.find("{")
    if start == -1:
        return text.strip()
    depth = 0
    for i in range(start, len(s)):
        if s[i] == "{":
            depth += 1
        elif s[i] == "}":
            depth -= 1
            if depth == 0:
                return s[start:i+1].strip()
    return text.strip()


def _sanitize_json_text(txt: str) -> str:
    """L√†m s·∫°ch text ƒë·ªÉ tr√°nh l·ªói JSON: b·ªè comment, ngo·∫∑c tr√≤n, xu·ªëng d√≤ng th·ª´a."""
    txt = re.sub(r'\([^)]*\)', '', txt)  # b·ªè (comment)
    txt = re.sub(r'//.*', '', txt)       # b·ªè comment //
    txt = re.sub(r'#.*', '', txt)        # b·ªè comment #
    txt = txt.replace('\n', ' ')         # g·ªôp d√≤ng
    txt = txt.replace('\r', '')
    return txt.strip()


def _coerce_schema(obj: dict) -> dict:
    """√âp schema JSON v·ªÅ chu·∫©n."""
    if not isinstance(obj, dict):
        return {"score": 0, "matched_skills": [], "missing_skills": [], "reason": str(obj)[:200]}
    out = {}
    try:
        val = obj.get("score", 0)
        if isinstance(val, (int, float)):
            out["score"] = int(val)
        else:
            out["score"] = int(float(str(val).replace("%", "").strip()) if str(val).replace(".", "", 1).isdigit() else 0)
    except Exception:
        out["score"] = 0

    out["matched_skills"] = list(obj.get("matched_skills", []))
    out["missing_skills"] = list(obj.get("missing_skills", []))
    out["reason"] = str(obj.get("reason", ""))[:500]
    return out


# ------------------ Main Evaluation ------------------
def evaluate_match(jd_text: str, cv_text: str):
    _log("\n=== ü§ñ EVALUATING MATCH WITH GEMINI ===")
    try:
        if not jd_text.strip() or not cv_text.strip():
            _log("‚ö†Ô∏è Empty JD or CV text, skipping evaluation.")
            return {"score": 0, "matched_skills": [], "missing_skills": [], "reason": "Empty input text."}

        prompt = f"""
You are an experienced recruiter. Evaluate how well this CV fits the job.

JD:
{jd_text}

CV:
{cv_text}

Return ONLY valid JSON (no code fences, no markdown, no explanation):
{{
  "score": 40-100,
  "matched_skills": [],
  "missing_skills": [],
  "reason": "1-2 sentence summary"
}}
"""

        model = gemini.GenerativeModel("gemini-2.5-flash")
        _log("üïê Sending request to Gemini...")
        response = model.generate_content(prompt)
        raw = (response.text or "").strip()

        if not raw:
            _log("‚ö†Ô∏è Gemini returned empty response.")
            return {"score": 0, "matched_skills": [], "missing_skills": [], "reason": "Gemini returned empty response"}

        _log("‚úÖ Raw Gemini response (truncated if long):")
        _log(raw[:800] + ("..." if len(raw) > 800 else ""))

        cleaned = _strip_code_fence(raw)
        cleaned = _extract_json_block(cleaned)
        cleaned = _sanitize_json_text(cleaned)

        try:
            parsed = json.loads(cleaned)
            parsed = _coerce_schema(parsed)
            _log("‚úÖ Parsed JSON successfully.")
            return parsed
        except json.JSONDecodeError as e:
            _log(f"‚ùå JSON decode failed: {e}")
            _log("‚ö†Ô∏è Cleaned content fallback:")
            _log(cleaned[:400])
            return {"score": 0, "matched_skills": [], "missing_skills": [], "reason": cleaned[:200]}

    except Exception as e:
        _log(f"‚ùå Unexpected error during LLM evaluation: {e}")
        traceback.print_exc()
        return {"score": 0, "matched_skills": [], "missing_skills": [], "reason": str(e)[:200]}
